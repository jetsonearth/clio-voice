import Foundation

/// Centralized API configuration for easy switching between environments
struct APIConfig {
    // MARK: - Environment Configuration
    
    /// Current API environment
    static let environment: APIEnvironment = .flyio // Switch back to Fly.io proxy
    
    enum APIEnvironment {
        case vercel
        case railway
        case koyeb
        case cloudflare
        case flyio
        
        var baseURL: String {
            switch self {
            case .vercel:
                return "https://www.cliovoice.com/api"
            case .railway:
                return "https://api.cliovoice.com/api" // Custom domain with persistent connections
            case .koyeb:
                return "https://koyeb.cliovoice.com/api" // Koyeb deployment with HTTP/2 and keep-alive
            case .cloudflare:
                return "https://clio-voice-backend.jetson-earth.workers.dev/api" // Cloudflare Workers edge deployment
            case .flyio:
                return "https://fly.cliovoice.com/api" // Fly.io deployment
            }
        }
        
        var displayName: String {
            switch self {
            case .vercel:
                return "Vercel (Legacy)"
            case .railway:
                return "Railway (Optimized)"
            case .koyeb:
                return "Koyeb (HTTP/2 + Keep-Alive)"
            case .cloudflare:
                return "Cloudflare Workers (Global Edge)"
            case .flyio:
                return "Fly.io"
            }
        }
    }
    
    // MARK: - API Endpoints
    
    /// Base API URL for current environment
    static var apiBaseURL: String {
        return environment.baseURL
    }
    
    /// LLM proxy endpoint (Groq-focused)
    static var llmProxyURL: String {
        return "\(apiBaseURL)/llm/proxy"
    }
    
    /// Gemini proxy endpoint (Gemini-focused) 
    static var geminiProxyURL: String {
        return "\(apiBaseURL)/llm/gemini"
    }
    
    /// Secure ASR temporary key endpoint (already implemented correctly)
    static var asrTempKeyURL: String {
        return "\(apiBaseURL)/asr/temp-key"
    }
    
    /// Authentication endpoint
    static var authSessionURL: String {
        switch environment {
        case .vercel, .railway:
            return "\(apiBaseURL)/auth/session-inline"
        case .koyeb, .cloudflare, .flyio:
            return "\(apiBaseURL)/auth/session"
        }
    }
    
    /// Usage tracking endpoint
    static var usageTrackURL: String {
        return "\(apiBaseURL)/usage/track"
    }
    
    /// Health check endpoint  
    static var healthCheckURL: String {
        switch environment {
        case .vercel:
            return "https://www.cliovoice.com/health"
        case .railway:
            return "https://api.cliovoice.com/health"
        case .koyeb:
            return "https://koyeb.cliovoice.com/health/ping"
        case .cloudflare:
            return "https://clio-voice-backend.jetson-earth.workers.dev/health"
        case .flyio:
            return "https://fly.cliovoice.com/health"
        }
    }
    
    /// LLM Keep-alive endpoint for maintaining proxy connection warmth
    static var llmKeepAliveURL: String {
        return "\(apiBaseURL)/llm/keepalive"
    }
    
    // MARK: - Performance Expectations
    
    /// Expected latency improvement with optimized backends
    static var expectedImprovements: [String: String] {
        switch environment {
        case .vercel:
            return [:]
        case .railway:
            return [
                "LLM Latency": "2400ms ‚Üí 600ms (4x faster)",
                "Connection Reuse": "Cold start every request ‚Üí HTTP/2 pooling",
                "Geographic Routing": "Edge routing overhead ‚Üí Direct server connection",
                "Architecture": "Serverless functions ‚Üí Always-on containers"
            ]
        case .koyeb:
            return [
                "Connection Reuse": "Cold start ‚Üí Persistent connections with keep-alive",
                "TLS Handshake": "1600ms overhead eliminated after first request",
                "Protocol": "HTTP/1.1 workarounds ‚Üí Native HTTP/2 support",
                "Keep-Alive": "60s Railway timeout ‚Üí 95s + indefinite with pings"
            ]
        case .cloudflare:
            return [
                "Edge Computing": "Server round-trip ‚Üí Edge processing in 200+ locations",
                "Cold Start": "Zero cold start with always-on Workers",
                "Geographic": "Automatic routing to nearest Cloudflare data center",
                "Protocol": "Native HTTP/3 and TLS 1.3 support"
            ]
        case .flyio:
            return [
                "Container Persistence": "No cold starts with always-on containers",
                "Network": "Optimized for Singapore/China connectivity",
                "Architecture": "Dedicated resources vs shared serverless"
            ]
        }
    }
    
    // MARK: - Debug Information
    
    /// Log current configuration for debugging
    static func logConfiguration() {
        print("üîß [API-CONFIG] Environment: \(environment.displayName)")
        print("üîß [API-CONFIG] Base URL: \(apiBaseURL)")
        print("üîß [API-CONFIG] Groq Proxy: \(llmProxyURL)")
        print("üîß [API-CONFIG] Gemini Proxy: \(geminiProxyURL)")
        print("üîß [API-CONFIG] ASR Temp Key: \(asrTempKeyURL)")
        
        if environment != .vercel {
            print("üöÄ [API-CONFIG] Expected improvements:")
            for (key, value) in expectedImprovements {
                print("   ‚Ä¢ \(key): \(value)")
            }
        }
    }
}

// MARK: - Migration Helper

extension APIConfig {
    /// Check if we're using an optimized backend
    static var isUsingOptimizedBackend: Bool {
        return environment != .vercel
    }
    
    /// Get migration status message
    static var migrationStatus: String {
        switch environment {
        case .vercel:
            return "‚ö†Ô∏è Using legacy Vercel backend (slow). Switch to Cloudflare Workers for 12x performance improvement."
        case .railway:
            return "‚úÖ Using Railway backend. Consider Cloudflare Workers for global edge computing."
        case .koyeb:
            return "üöÄ Using Koyeb with HTTP/2 + keep-alive. Optimal performance: ~400ms LLM latency."
        case .cloudflare:
            return "üåü Using Cloudflare Workers - Global edge computing with <200ms latency worldwide."
        case .flyio:
            return "üéØ Using Fly.io - Optimized for Asia-Pacific users with ~300ms latency."
        }
    }
}
